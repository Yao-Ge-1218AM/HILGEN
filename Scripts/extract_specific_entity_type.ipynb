{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htenm-yc5qGX"
      },
      "source": [
        "extract symptom from original datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q3oAwJ85oFS"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/train.txt\",\"r\") as f:\n",
        "  with open(\"/content/train-all-Disease.txt\",\"w\") as wf:\n",
        "    lines = f.readlines()\n",
        "    i = 0\n",
        "    start = end = 0\n",
        "    tag = 0\n",
        "    for i in range(len(lines)):\n",
        "      line = lines[i]\n",
        "      if(line==\"\\n\"):\n",
        "        end = i\n",
        "        if(tag==1): # loop write the lines: from start to end\n",
        "          for j in range(start,end+1):\n",
        "            wf.write(lines[j])\n",
        "          tag = 0\n",
        "        start = end + 1\n",
        "      else:\n",
        "        line = line.strip(\"\\n\")\n",
        "        if(line.endswith(\"DEVICE\")):\n",
        "          tag = 1\n",
        "          #print(line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqly5sTHBZNZ"
      },
      "source": [
        "随机抽取250个"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei1fEHb8Bgss",
        "outputId": "8991691e-756f-4324-d2c9-4711c0b64026"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[43, 83, 91, 60, 11, 9, 13, 3, 62, 55]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import random\n",
        "random.sample(range(0,100),10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71Z3N4KEB9yy"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/train-all-Disease.txt\",\"r\") as f:\n",
        "  lines = f.readlines()\n",
        "  count = 0\n",
        "  for line in lines:\n",
        "    if(line==\"\\n\"):\n",
        "      count+=1\n",
        "\n",
        "index = random.sample(range(0,count),5)\n",
        "\n",
        "with open(\"/content/train-all-Disease.txt\",\"r\") as f:\n",
        "  with open(\"/content/train-5-Disease.txt\",\"w\") as wf:\n",
        "    lines = f.readlines()\n",
        "    i = 0\n",
        "    start = end = 0\n",
        "    c = 0\n",
        "    for i in range(len(lines)):\n",
        "      line = lines[i]\n",
        "      if(line==\"\\n\"):\n",
        "        c += 1\n",
        "        end = i\n",
        "        if(c in index):\n",
        "          for j in range(start,end+1):\n",
        "            wf.write(lines[j])\n",
        "        start = end + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaiqqHUXD2EP",
        "outputId": "78eaa362-7a08-40df-c03c-ee3b87e2674b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26044"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3imE-NfHD6Ni"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/train-5-Disease.txt\",\"r\") as f:\n",
        "  lines = f.readlines()\n",
        "  count = 0\n",
        "  for line in lines:\n",
        "    if(line==\"\\n\"):\n",
        "      count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyss8zlKD8jq",
        "outputId": "b22e0301-6901-4506-a271-6b3c3a8159e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEb86Dta8L0c"
      },
      "source": [
        "分割线，下面需要的是，extract training data中的所有disease！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJY2Z6ZJylvt"
      },
      "source": [
        "再分割一下，后面的scripts主要就是从这里分开的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKCmCi9REY9C"
      },
      "source": [
        "step 1: Extract all concepts from training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiC-dEKm8S6P",
        "outputId": "32ea9f86-29d8-46e0-ea81-02127866683a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'granulocytopenia', 'hypertensive', 'atrial tachycardia', 'intraventricular conduction abnormalities', 'toxicity', 'intra-Hisian block', 'hypotensive', 'hyperalgesia'}\n",
            "granulocytopenia\n",
            "hypertensive\n",
            "atrial tachycardia\n",
            "intraventricular conduction abnormalities\n",
            "toxicity\n",
            "intra-Hisian block\n",
            "hypotensive\n",
            "hyperalgesia\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/train.txt\",\"r\") as f:\n",
        "  lines = f.readlines()\n",
        "  i = 0\n",
        "  tmp = []\n",
        "  entity = set()\n",
        "  for i in range(len(lines)-1):\n",
        "    line = lines[i].strip(\"\\n\")\n",
        "    next_line = lines[i+1].strip(\"\\n\")\n",
        "    if(line.endswith(\"B-Disease\")):\n",
        "      tmp = []\n",
        "      if(next_line.endswith(\"I-Disease\")):     # need to change I-GENE\n",
        "        tmp.append(line.split(\" \")[0])\n",
        "        while(next_line.endswith(\"I-Disease\")):\n",
        "          tmp.append(next_line.split(\" \")[0])\n",
        "          i+=1\n",
        "          next_line = lines[i+1].strip(\"\\n\")\n",
        "        phrase = \"\"\n",
        "        for j in range(len(tmp)-1):\n",
        "          #wf.write(tmp[j] + \" \")\n",
        "          phrase += tmp[j]\n",
        "          phrase += \" \"\n",
        "        #wf.write(tmp[j+1] + \"\\n\")\n",
        "        phrase += tmp[j+1]\n",
        "        #phrase += \"\\n\"\n",
        "        entity.add(phrase)\n",
        "      else:\n",
        "        entity.add(line.split(\" \")[0])\n",
        "        #wf.wirte(line + \"\\n\")\n",
        "print(entity)\n",
        "with open(\"/content/train-disease-entities.txt\",\"w\") as wf:\n",
        "  for ent in entity:\n",
        "    print(ent)\n",
        "    wf.write(ent + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmTnRMuFMf71"
      },
      "source": [
        "Step 2: write the scripts for search for all related concepts\n",
        "\n",
        "1. save all urls\n",
        "2. 每个entity要建立一个文件，以entity命名的\n",
        "3. 根据每个url，得到一个json文件\n",
        "4. parse json文件，得到name，和cui\n",
        "5. name可以直接生成每个entity对应的related concepts文件，但是只要10个就够了。\n",
        "6. cui保存起来做字典，供后面查parents、children使用。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaLmbxRIMhk5"
      },
      "outputs": [],
      "source": [
        "#apikey = \"7e7e253a-1168-4530-b8b4-24cb7daaa701\"\n",
        "#api_url = \"https://uts-ws.nlm.nih.gov/rest/search/current\"\n",
        "\n",
        "#with open(\"/content/train-disease-entities.txt\",\"r\") as f:\n",
        "  #with open(\"/content/train-disease-url-concepts.txt\",\"w\") as wf:\n",
        "    #lines = f.readlines()\n",
        "    #for line in lines:\n",
        "      #string = line.strip(\"\\n\")\n",
        "      #url = api_url + \"?apiKey=\" + apikey + \"&string=\" + string\n",
        "      #wf.write(url+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGQpE0chqzj8"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/related-concepts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gx-RQyWGpj_"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/related-concepts/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tiB3LuAH3AD"
      },
      "source": [
        "每个entity要建立一个文件，以entity命名的\n",
        "\n",
        "根据每个url，得到一个json文件\n",
        "\n",
        "parse json文件，得到name\n",
        "\n",
        "name可以直接生成每个entity对应的related concepts文件，但是只要10个就够了。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ8TKc1w_j1p"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "apikey = \"7e7e253a-1168-4530-b8b4-24cb7daaa701\"\n",
        "api_url = \"https://uts-ws.nlm.nih.gov/rest/search/current\"\n",
        "\n",
        "related_concepts_path = \"/content/related-concepts/\"\n",
        "\n",
        "with open(\"/content/train-disease-entities.txt\",\"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      #print(line)\n",
        "      string = line.strip(\"\\n\")\n",
        "      url = api_url + \"?apiKey=\" + apikey + \"&string=\" + string\n",
        "      response = requests.get(url)\n",
        "\n",
        "      data = json.loads(response.content)\n",
        "\n",
        "      with open(related_concepts_path + line.strip(\"\\n\") + \".txt\",\"a\") as wf:\n",
        "        i = 1\n",
        "        for concept in data['result']['results']:\n",
        "          if(i<=10):\n",
        "            #print(concept['name'])\n",
        "            wf.write(concept['name']+\"\\n\")\n",
        "          i+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqbKDTYk6ONM"
      },
      "source": [
        "再分割，尝试一下解析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5PWx1kX6RIs"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# 解析出来的网址\n",
        "url = 'https://uts-ws.nlm.nih.gov/rest/search/current?apiKey=7e7e253a-1168-4530-b8b4-24cb7daaa701&string=granulocytopenia'\n",
        "\n",
        "# 获取网址的内容\n",
        "response = requests.get(url)\n",
        "\n",
        "# 将响应内容转换为 Python 对象\n",
        "data = json.loads(response.content)\n",
        "\n",
        "#print(data['result']['results'])\n",
        "i = 1\n",
        "for concept in data['result']['results']:\n",
        "  if(i<=10):\n",
        "    print(concept['name'])\n",
        "  i+=1\n",
        "\n",
        "# 将 Python 对象保存为 json 文件\n",
        "#with open('/content/data.json', 'w') as f:\n",
        "    #json.dump(data, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjNM6EOFIHEw"
      },
      "source": [
        "Parents and Children\n",
        "\n",
        "得到given concept的cui\n",
        "\n",
        "根据cui去找它的parent和children\n",
        "\n",
        "也是最多只要10个就行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYJ7J-koPd_B"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/parents/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h60O06e6PfqR"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/parents/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWu63ZRShIPl"
      },
      "source": [
        "得到given concept的cui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IDAqlTITDQt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "apikey = \"7e7e253a-1168-4530-b8b4-24cb7daaa701\"\n",
        "api_url = \"https://uts-ws.nlm.nih.gov/rest/search/current\"\n",
        "\n",
        "related_concepts_path = \"/content/related-concepts/\"\n",
        "\n",
        "with open(\"/content/train-disease-entities.txt\",\"r\") as f:\n",
        "  with open(\"/content/train-disease-uis.txt\",\"w\") as wf:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      #print(line)\n",
        "      string = line.strip(\"\\n\")\n",
        "      url = api_url + \"?apiKey=\" + apikey + \"&string=\" + string + \"&returnIdType=code&sabs=SNOMEDCT_US\"\n",
        "      response = requests.get(url)\n",
        "\n",
        "      #print(string)\n",
        "      data = json.loads(response.content)\n",
        "      if(len(data['result']['results'])!=0):\n",
        "        wf.write(string + \"\\t\" + data['result']['results'][0]['ui']+\"\\n\")\n",
        "        #print(data['result']['results'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXvz1JlghK_4"
      },
      "source": [
        "根据cui去找它的parent和children\n",
        "\n",
        "也是最多只要10个就行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SezXkqAFPMrm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "apikey = \"7e7e253a-1168-4530-b8b4-24cb7daaa701\"\n",
        "api_url = \"https://uts-ws.nlm.nih.gov/rest/content/current/source/SNOMEDCT_US/\"\n",
        "\n",
        "parents_children_path = \"/content/parents/\"\n",
        "\n",
        "with open(\"/content/train-disease-uis.txt\",\"r\") as f:\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    #print(line)\n",
        "    string = line.strip(\"\\n\").split(\"\\t\")[1]\n",
        "    #print(string)\n",
        "    url = api_url + string + \"/parents?apiKey=\" + apikey\n",
        "    #print(url)\n",
        "    response = requests.get(url)\n",
        "\n",
        "    data = json.loads(response.content)\n",
        "\n",
        "    with open(parents_children_path + line.strip(\"\\n\").split(\"\\t\")[0] + \".txt\",\"a\") as wf:\n",
        "      i = 1\n",
        "      for concept in data['result']:\n",
        "        if(i<=10):\n",
        "          #print(concept['name'])\n",
        "          wf.write(concept['name']+\"\\n\")\n",
        "        i+=1\n",
        "\n",
        "    url = api_url + string + \"/children?apiKey=\" + apikey\n",
        "    response = requests.get(url)\n",
        "\n",
        "    data = json.loads(response.content)\n",
        "    #print(url,data)\n",
        "\n",
        "    file_name = parents_children_path + line.strip(\"\\n\").split(\"\\t\")[0] + \".txt\"\n",
        "    if(os.path.exists(file_name)):\n",
        "      with open(file_name,\"r\") as rf:\n",
        "        lines = rf.readlines()\n",
        "        i = len(lines)+1\n",
        "        #print(file_name,i)\n",
        "    else:\n",
        "      i = 1\n",
        "    with open(file_name,\"a\") as wf:\n",
        "      #if(exists, i = lens; else: i = 0)\n",
        "      if('result' in data):\n",
        "        for concept in data['result']:\n",
        "          if(i<=10):\n",
        "            #print(concept['name'])\n",
        "            wf.write(concept['name']+\"\\n\")\n",
        "          i+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v7Y8tToIKEM",
        "outputId": "af28cf2c-27dc-4ff9-b982-a8d6b6852ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closed fracture of upper limb\n"
          ]
        }
      ],
      "source": [
        "url = \"https://uts-ws.nlm.nih.gov/rest/content/current/source/SNOMEDCT_US/9468002/parents?apiKey=7e7e253a-1168-4530-b8b4-24cb7daaa701\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "data = json.loads(response.content)\n",
        "\n",
        "print(data['result'][0]['name'])\n",
        "\n",
        "with open('/content/data.json', 'w') as f:\n",
        "    json.dump(data, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM2C9UzbjbHk"
      },
      "source": [
        "Siblings\n",
        "\n",
        "得到given concept的parent的cui\n",
        "\n",
        "根据cui去找它的children\n",
        "\n",
        "也是最多只要10个就行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhU47nfOriHv"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/siblings/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUIN9p_Hrjyw"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/siblings/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujdKOJh-rK1g"
      },
      "source": [
        "得到given concept的parent的cui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyxffMBhjkDn"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "apikey = \"7e7e253a-1168-4530-b8b4-24cb7daaa701\"\n",
        "api_url = \"https://uts-ws.nlm.nih.gov/rest/content/current/source/SNOMEDCT_US/\"\n",
        "\n",
        "with open(\"/content/train-disease-uis.txt\",\"r\") as f:\n",
        "  with open(\"/content/train-disease-parents-uis.txt\",\"w\") as wf:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      #print(line)\n",
        "      string = line.strip(\"\\n\").split(\"\\t\")[1]\n",
        "      #print(string)\n",
        "      url = api_url + string + \"/parents?apiKey=\" + apikey\n",
        "      #print(url)\n",
        "      response = requests.get(url)\n",
        "\n",
        "      data = json.loads(response.content)\n",
        "\n",
        "      if('result' in data):\n",
        "        wf.write(line.strip(\"\\n\").split(\"\\t\")[0] + \"\\t\" + data['result'][0]['ui']+\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhZwf6yyrMnM"
      },
      "source": [
        "根据cui去找它的children\n",
        "\n",
        "也是最多只要10个就行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1OJzKmKqxZq"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "apikey = \"7e7e253a-1168-4530-b8b4-24cb7daaa701\"\n",
        "api_url = \"https://uts-ws.nlm.nih.gov/rest/content/current/source/SNOMEDCT_US/\"\n",
        "\n",
        "parents_children_path = \"/content/siblings/\"\n",
        "\n",
        "with open(\"/content/train-disease-parents-uis.txt\",\"r\") as f:\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    #print(line)\n",
        "    string = line.strip(\"\\n\").split(\"\\t\")[1]\n",
        "    #print(string)\n",
        "    url = api_url + string + \"/children?apiKey=\" + apikey\n",
        "    response = requests.get(url)\n",
        "\n",
        "    data = json.loads(response.content)\n",
        "    #print(url,data)\n",
        "\n",
        "    file_name = parents_children_path + line.strip(\"\\n\").split(\"\\t\")[0] + \".txt\"\n",
        "    i = 1\n",
        "    with open(file_name,\"a\") as wf:\n",
        "      if('result' in data):\n",
        "        for concept in data['result']:\n",
        "          if(i<=10):\n",
        "            #print(concept['name'])\n",
        "            wf.write(concept['name']+\"\\n\")\n",
        "          i+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otcLUPzUrvPm"
      },
      "source": [
        "zip three folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgDMsEHkr3HT"
      },
      "outputs": [],
      "source": [
        "!tar -zcvf bc5cdr-parents.tar.gz /content/parents/\n",
        "!tar -zcvf bc5cdr-related-concepts.tar.gz /content/related-concepts/\n",
        "!tar -zcvf bc5cdr-siblings.tar.gz /content/siblings/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waFGU1JGk0_1"
      },
      "source": [
        "calculate the frequency of text， copy from EntLM scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEfcSo4hk0mz"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/train.txt\") as f:\n",
        "  text = f.readlines()\n",
        "  DEVICE = []\n",
        "  HEALTHPLAN = []\n",
        "  BIOID = []\n",
        "  IDNUM = []\n",
        "  for line in text:\n",
        "    if(line!=\"\\n\"):\n",
        "      new_line = line.strip(\"\\n\").split(\" \")\n",
        "      if(new_line[1]!=\"O\"):\n",
        "        #print(line)\n",
        "        #SpecificDisease, Modifier, DiseaseClass\n",
        "        if(new_line[1].endswith(\"DEVICE\")):\n",
        "          DEVICE.append(new_line[0])\n",
        "        elif(new_line[1].endswith(\"HEALTHPLAN\")):\n",
        "          HEALTHPLAN.append(new_line[0])\n",
        "        elif(new_line[1].endswith(\"BIOID\")):\n",
        "          BIOID.append(new_line[0])\n",
        "        elif(new_line[1].endswith(\"IDNUM\")):\n",
        "          IDNUM.append(new_line[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp8Oa81alC5f"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "punctuation_string = string.punctuation\n",
        "#print(punctuation_string)\n",
        "\n",
        "DEVICE_new = []\n",
        "\n",
        "for word in DEVICE:\n",
        "  for i in punctuation_string:\n",
        "    word = word.replace(i,\"\")\n",
        "  #print(word)\n",
        "  DEVICE_new.append(word.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-N0qmeNlHrc",
        "outputId": "c7363cb8-7794-43c7-b587-0a32fc8686d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'193062closure': 1, '358892': 1, '8068103total': 1, '17722gnp': 1, '30058catheters': 1, '56520yog': 1, '9ys7ez': 1})\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "frequency = collections.Counter(DEVICE_new)\n",
        "print(frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmEAAmmbluJp"
      },
      "source": [
        "Transform data from txt to json,  copy from EntLM scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBNd3tOUlHmQ"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/5shot-1.txt\",\"r\") as f:\n",
        "  with open(\"/content/5shot-1.json\",\"a\") as wf:\n",
        "    text = f.readlines()\n",
        "    word = []\n",
        "    label = []\n",
        "    for line in text:\n",
        "      if(line==\"\\n\"):\n",
        "        wf.write('{\"text\": [')\n",
        "        count = 0\n",
        "        for w in word:\n",
        "          count+=1\n",
        "          if(count!=len(word)):\n",
        "            wf.write('\"'+w+'\", ')\n",
        "          else:\n",
        "            wf.write('\"'+w+'\"')\n",
        "        wf.write('], \"label\": [')\n",
        "        count = 0\n",
        "        for l in label:\n",
        "          count+=1\n",
        "          if(count!=len(label)):\n",
        "            wf.write('\"'+l+'\", ')\n",
        "          else:\n",
        "            wf.write('\"'+l+'\"')\n",
        "        wf.write(']}' +\"\\n\")\n",
        "        word = []\n",
        "        label = []\n",
        "      else:\n",
        "        new_line = line.strip(\"\\n\").split(\" \")\n",
        "        word.append(new_line[0])\n",
        "        label.append(new_line[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}